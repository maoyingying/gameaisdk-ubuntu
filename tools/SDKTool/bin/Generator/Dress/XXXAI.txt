#!/usr/bin/env python
# coding: utf-8

import time
import logging

import numpy as np

from .Handler.GuideHandler import GuideHandler
from .Handler.HairHandler import HairHandler
from .Handler.DressHandler import DressHandler
from .Handler.CoatHandler import CoatHandler
from .Handler.ShoesHandler import ShoesHandler
from .Handler.FinishHandler import FinishHandler

from aimodel.AIModel import AIModel

DEFAULT_PRIORITY = 20

HANDLERS_LIST = [{'Class': GuideHandler, 'Priority': 50, 'Handler': None},
                 {'Class': HairHandler, 'Priority': 30, 'Handler': None},
                 {'Class': DressHandler, 'Priority': 40, 'Handler': None},
                 {'Class': CoatHandler, 'Priority': 30, 'Handler': None},
                 {'Class': ShoesHandler, 'Priority': 30, 'Handler': None},
                 {'Class': FinishHandler, 'Priority': 10, 'Handler': None}
                ]

class XXXAI(AIModel):
    # 构造函数
    def __init__(self):
        AIModel.__init__(self)

    # 初始化函数，参数agentEnv为 Env插件类实例对象
    def Init(self, agentEnv):
        self.agentEnv = agentEnv

        if not self._InitHandlers():
            self.logger.error('Handlers init failed')
            return False

        return True

    # 退出函数
    def Finish(self):
        for item in HANDLERS_LIST:
            handler = item.get('Handler')
            if handler is not None:
                handler.Finish()

        return True

    # 检测到每一局游戏开始后，AI算法进行的操作可以在此处实现，如一些变量的重置等
    def OnEpisodeStart(self):
        pass

    # 检测到每一局游戏结束后，AI算法进行的操作可以在此处实现
    def OnEpisodeOver(self):
        pass

    # 当加载进入游戏场景时，需要进行的操作可以在此处实现
    def OnEnterEpisode(self):
        pass

    # 当离开退出游戏场景时，需要进行的操作可以在此处实现
    def OnLeaveEpisode(self):
        pass

    # 训练AI操作的每一个step实现,通常强化学习算法需要实现此接口,基于规则的AI无需训练,不需要实现此接口
    def TrainOneStep(self):
        pass

    # AI测试的每一个step实现，通常实现为agentEnv获取游戏状态数据，然后根据AI算法输出对应的游戏操作
    def TestOneStep(self):
        # 随机更新一个handler
        p = np.array([item.get('Priority', DEFAULT_PRIORITY) for item in HANDLERS_LIST])
        p = p / p.sum()
        item = np.random.choice(HANDLERS_LIST, p=p.ravel())
        handler = item.get('Handler')
        if handler is not None:
            self.agentEnv.GetState()
            self.logger.info("update handler: {}".format(handler.__class__.__name__))
            handler.Update()
            time.sleep(0.2)

        # 顺序更新所有handler
        # for item in HANDLERS_LIST:
        #     handler = item.get('Handler')
        #     if handler is not None:
        #         self.agentEnv.GetState()
        #         self.logger.info("update handler: {}".format(handler.__class__.__name__))
        #         handler.Update()
        #         time.sleep(0.2)

    def _InitHandlers(self):
        for item in HANDLERS_LIST:
            handler = item['Class'](self.agentEnv)
            if not handler.Initialize():
                self.logger.error('Init Handler {} failed'.format(item['Class']))
                return False

            item['Handler'] = handler

        return True
